# Fashion MNIST Dataset

Fashion MNIST is a dataset containing images of clothing items. It serves as a benchmark for machine learning algorithms, particularly for image classification tasks. In this assignment, you will be tasked with using a Multilayer Perceptron (MLP) implemented with PyTorch to classify these images into their respective categories. The primary goal is to maximize the accuracy of the classification model.

## Objective

The main objective of this assignment is to familiarize students with:
1. The Fashion MNIST dataset.

2. Implementing a Multilayer Perceptron (MLP) using PyTorch.

3. Training and optimizing the MLP model to achieve higher accuracy on the Fashion MNIST dataset.

## Dataset Description

Fashion MNIST is a dataset that consists of 60,000 training images and 10,000 testing images. Each image is a 28x28 grayscale image, belonging to one of 10 categories, representing different types of clothing and fashion items.

### The categories are:

1. T-shirt/top

2. Trouser

3. Pullover

4. Dress

5. Coat

6. Sandal

7. Shirt

8. Sneaker

9. Bag

10. Ankle boot

## Tasks

1. Data Preparation

    1. Download the Fashion MNIST dataset.
    2. Preprocess the dataset (e.g., normalization, resizing). 
    3. c. Split the dataset into training and testing sets.


2. Model Architecture

    1. Design a Multilayer Perceptron (MLP) architecture using PyTorch.
    2. Experiment with different architectures, including variations in the number of layers, activation functions, and hidden units.


3. Training

    1. Train the MLP model using the training dataset.
    2. Experiment with different optimization algorithms (e.g., SGD, Adam) and learning rates. 
    3. Monitor the training process, including loss and accuracy metrics.


4. Evaluation

    1. Evaluate the trained model using the testing dataset.
    2. Calculate the accuracy of the model on the testing dataset. 
    3. Analyze the performance of the model and identify areas for improvement.


5. Hyperparameter Tuning

    1. Perform hyperparameter tuning to optimize the performance of the model.
    2. Experiment with different hyperparameters such as batch size, number of epochs, and learning rate.


6. Visualization

    1. Visualize the training process (e.g., loss curve, accuracy curve).
    2. Visualize sample predictions and compare them with the ground truth labels.


## Note

● Ensure proper code documentation and comments for better understanding.

● Refer to PyTorch documentation and tutorials for guidance on implementing MLP models.

● Experimentation is encouraged to improve model accuracy, but make sure to document all changes and observations thoroughly.